---
title: "Image Filtering"
author: "Thomas Smale"
date: "5/7/2022"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(gridExtra)
library(ggplot2)
library(gridExtra)
library(tidyverse)
library(jpeg)
library(plotly)
library(reticulate)
use_python('/usr/local/bin/python3')
```

# Intro

Images have important applications in computer vision models. Images are represented in a computer using tensors or arrays. An image will be a matrix expressing its height, width, and number of components. The number of components determines if the image is colored or gray scale. Colored images may have 3 components, red, green, and blue. Gray scale images will have one component. The pixels in an image can range from [0, 1], [0, 255], or other options depending on it's configuration. 0 will mean the pixel has no red at that element and the max value like 1 will mean it's completely red. 

# Rotating images

Here we are reading in an image and formatting as a 3 dimensional array. There are three components, for red, green, and blue. Each component is a 2 dimensional array with width 159 and height 240. By using techniques like the transpose of a matrix we are able to rotate the image. 

```{r}
#Clockwise rotations
img <- readJPEG('images/mud.jpeg')
dims <- dim(img)
red <- img[,,1]
green <- img[,,2]
blue <- img[,,3]
#90 degrees 
#Reverse order of rows, take transpose
r <- t(red[nrow(red):1,])
g <- t(green[nrow(green):1,])
b <- t(blue[nrow(blue):1,])
ninety <- array(c(r, g, b), dim=c(dim(b), 3))
#180 degrees 
#Reverse order of rows and cols
r <- red[nrow(red):1, ncol(red):1]
g <- green[nrow(green):1, ncol(green):1]
b <- blue[nrow(blue):1, ncol(blue):1]
oneeighty <- array(c(r, g, b), dim=c(dim(b), 3))
#270 degrees 
#Take transpose, reverse column order
r <- t(red)[ncol(red):1,]
g <- t(green)[ncol(green):1,]
b <- t(blue)[ncol(blue):1,]
twoseventy <- array(c(r, g, b), dim=c(dim(b), 3))
```

```{r include=FALSE}
# Display new images
# Layout new settings
layout <- c(2,2)
op <- par(
  mar = c(1, 1, 1, 1),
  mfrow = layout,
  bty = "n",
  omi = c(0, 0, 0, 0), 
  oma = c(0, 0, 2, 0)
)
#First image
dims <- dim(img)
plot(
  c(0, dims[1]),
  c(dims[2], 0),
  type = "n",
  xlab = "",
  ylab = "",
  xaxt = "n",
  yaxt = "n",
  frame.plot = FALSE,
  main = "Original"
)
rasterImage(img, 0, 0, dims[1], dims[2], interpolate = FALSE)
#Second image
dims <- dim(ninety)
plot(
  c(0, dims[1]),
  c(dims[2], 0),
  type = "n",
  xlab = "",
  ylab = "",
  xaxt = "n",
  yaxt = "n",
  frame.plot = FALSE,
  main = "90"
)
rasterImage(ninety, 0, 0, dims[1], dims[2], interpolate = FALSE)
#Third image
dims <- dim(oneeighty)
plot(
  c(0, dims[1]),
  c(dims[2], 0),
  type = "n",
  xlab = "",
  ylab = "",
  xaxt = "n",
  yaxt = "n",
  frame.plot = FALSE,
  main = "180"
)
rasterImage(oneeighty, 0, 0, dims[1], dims[2], interpolate = FALSE)
#Fourth image
dims <- dim(twoseventy)
plot(
  c(0, dims[1]),
  c(dims[2], 0),
  type = "n",
  xlab = "",
  ylab = "",
  xaxt = "n",
  yaxt = "n",
  frame.plot = FALSE,
  main = "270"
)
rasterImage(twoseventy, 0, 0, dims[1], dims[2], interpolate = FALSE)
mtext(text="Clockwise Rotations", outer=TRUE, cex=1.5)
par(op)
```

# Gaussian Distribution aka Normal Distribution

The first step in detection edges is noise reduction To accomplish this we will use Gaussian filtering which is used to blur images and remove noise. $\sigma$ is the standard deviation of the distribution, which measures how spread out values are from the mean. A large standard deviation means there is high variance and a low standard deviation indicates low variance. A key component of the standard deviation is that +-1 standard deviations away from the mean represent 68% of the values. While +-2 standard deviations away from the mean account for 95% of the set. Finally, +- 3 standard deviations contain 98% of the values. We will take advantage of this to fit a kernal that represents the shape of this. The bell curve is a common way to visualize this. The center of the curve is the mean and the width of the curve gives an idea for the standard deviation. 

1 dimensional Gaussian function: 

$$G(x) = \frac {1}{\sqrt{2\pi\sigma^2}}e^\frac{-x^2}{2\sigma^2}$$

When working with images, we will use a 2 dimensional Gaussian function 
$$G(x, y) = \frac{1}{2\pi\sigma^2}e^\frac{x^2+y^2}{2\sigma^2}$$

The integral of the Gaussian Function also has importance.
$$I = \int_{-\infty}^{\infty}e(-x^2)dx=\sqrt{\pi}$$
* The square root of pi is the area under the graph of the Gaussian function
* So the area under the curve will equal about 1.772. 

```{r}
gaussian <- function(x) {
  part1 <- 1 / sqrt(2*pi*sd(x))
  part2 <- exp(1)^((-x^2)/(2*(sd(x)^2)))
  return(part1*part2)
}
gaussian2d <- function(x, y) {
  part1 <- 1 / (2*pi*sd(x*y)^2)
  part2 <- exp(1)^((-(x^2+y^2))/(2*(sd(x*y)^2)))
  return(part1*part2)
}
#The weight sets the standard deviation of the bell curve
#We will explore this later!
gaussian2d_fixed <- function(x, y, weight) {
  part1 <- 1 / (2*pi*(weight^2))
  part2 <- exp(1)^((-(x^2+y^2))/(2*(weight^2)))
  return(part1*part2)
}
gaussian_integral <- function(x) {
  
  return(exp(-x^2))
}

x <- y <- seq(-4, 4, .1)
gauss <- ggplot(mapping=aes(x, y=gaussian(x))) + geom_line() + 
  ggtitle("Gaussian function")
# gauss2d <- persp(x, y, z=outer(x,y,gaussian2d), 
#                  theta=20, main="2 Dimensional Gaussian Function")
gauss2d_interactive <- plot_ly(x=~x, y=~y, z=~outer(x, y, gaussian2d)) %>% 
  add_surface() %>%
  layout(title="2 Dimensional Gaussian Function") %>%
  layout(xaxis=(list(fixedrange=TRUE))) %>%
  layout(yaxis=(list(fixedrange=TRUE))) 
gauss_integral <- ggplot(mapping=aes(x, y=gaussian_integral(x))) + geom_line() +
  ggtitle("Gaussian Integral")
grid.arrange(gauss, gauss_integral, nrow=2)
```

### Creating a kernel 
A kernel is a square matrix of coefficients with an anchor point in the center. We refer to the center point aka anchor, as (0, 0). The rest of the points represent the distance from the anchor using pixels as a unit. We plug these values into the 2 dimensional Gaussian function to initialize the values of the kernel. The sum of the values in the kernel must equate to 1. The original output from the 2 dimensional Gaussian function will not equal 1. So we take the sum of the values outputted, set it as the denominator, and divide by 1. Then we multiply that, (1 / sum(x)) by all the values from the output. The sum of the values in the kernel will now equal 1. We use the kernel to apply convolutions to the image to produce edge detection. 

$$
\begin{array}{ccc}
{(1, 1)} & {(0, 1)} & {(1, 1)}\\
{(1, 0)} & {(0, 0)} & {(1, 0)}\\
{(1, 1)} & {(0, 1)} & {(1, 1)}
\end{array}
$$

```{r}
#Kernel size 3
x <- c(1, 0, 1, 
       1, 0, 1, 
       1, 0, 1)
y <- c(1, 1, 1,
       0, 0, 0, 
       1, 1, 1)
z <- gaussian2d_fixed(x, y, 5.5)
z <- z * (1 / sum(z))
z <- array(z, dim=c(sqrt(length(x)), sqrt(length(y))))
discrete_gauss3x3 <- plot_ly(x=~x, y=~y, z=~z) %>%
  add_surface() %>%
  layout(title="Discrete Approximation Kernel 3x3",
         xaxis=(list(fixedrange=TRUE)),
         yaxis=list(fixedrange=TRUE))
#Kernel size 5
x <- c(2, 1, 0, 1, 2,
       2, 1, 0, 1, 2,
       2, 1, 0, 1, 2,
       2, 1, 0, 1, 2,
       2, 1, 0, 1, 2)
y <- c(2, 2, 2, 2, 2,
       1, 1, 1, 1, 1,
       0, 0, 0, 0, 0,
       1, 1, 1, 1, 1,
       2, 2, 2, 2, 2)
z1_weight <- 1.0
z2_weight <- 5.0
z3_weight <- 10.0
z1 <- gaussian2d_fixed(x, y, z1_weight)
z2 <- gaussian2d_fixed(x, y, z2_weight)
z3 <- gaussian2d_fixed(x, y, z3_weight)
z1 <- z1 * (1 / sum(z1))
z2 <- z2 * (1 / sum(z2))
z3 <- z3 * (1 / sum(z3))
z1 <- array(z1, dim=c(sqrt(length(x)), sqrt(length(x))))
z2 <- array(z2, dim=c(sqrt(length(x)), sqrt(length(x))))
z3 <- array(z3, dim=c(sqrt(length(x)), sqrt(length(x))))
discrete_gauss5x5 <- plot_ly(x=~x, y=~y, z=~z1) %>%
  add_surface() %>%
  layout(title="Discrete Approximation Kernel 5x5")
z <- data.frame(z1=c(z1), z2=c(z2), z3=c(z3))
z <- pivot_longer(z, cols=c('z1', 'z2', 'z3'), names_to='weight')
colors <- c("#FDAE61", "#0000FF", "#00FF00")
plot(c(z1), col=colors[1], type='b', xlab="", xaxt="n", 
     main='Discrete Approximation of Gaussian Distribution')
legend("topright",
       legend = c(
         paste("Weight =", z1_weight)
         # paste("Weight =", z2_weight),
         # paste("Weight =", z3_weight)
       ),
       pch=19,
       col = colors[1])
```

2 important concepts conveyed in the graph above is that the kernel is symmetric and the overall shape resembles a bell curve. The different peaks represent 1, 2, and 3 standard deviations from the mean (center) of the bell curve. As the weight changes, the y-axis becomes smaller and smaller. This means that..?


# Convolution

Convolution is the process of applying the kernel over the original image. We place the anchor of kernel over every pixel in the image. We perform a matrix multiplication with the kernel and the pixel's neighbors. Then, compute the sum of the products. The output of this value is the new pixel value in the transformed image. 

When applying a kernel to an image, it may result in a smaller size. The output of the image can be calculated using this formula. 
```{r}
# Calculate the output size of image after applying filter and convolution 
# dim is width or height of image
# ksize is size of kernal
# padding is if we want a border or something like that
# stride is how much the filter increments by
new_size <- function(dim, ksize, padding, stride) {
  return(((dim-ksize+2*padding)/1)+1)
}
```

However, in this case we will be using a technique called zero padding. This pads the image with zero's so the result from the convolution is the original image size. The number of rows and columns of zero's we pad the original image with is calculated by the number of rows/columns in the kernel - 1. Then we apply the convolution, it's mathematical formula is given below.

### 2D convolution forumla 

$$y[i, j] = \sum_{m=-\infty}^{\infty} \sum_{n=-\infty}^{m=\infty}h[m, n]*x[i-m,j-n]$$

Here x is the input image and y is the output which is the new image. H is the kernel matrix. I and j iterate over the image while m and n deal with that of the kernel. 

When applying a 2d convolution using a gaussian filter it reduces the noise in the image. This gives the effect of blurring the image. 

##Graph image 
```{r}
mygauss <- function(x, y) {
  weight <- 5.5
  part1 <- 1 / (2*pi*(weight^2))
  part2 <- exp(1)^((-(x^2+y^2))/(2*(weight^2)))
  return(part1*part2)
}
img <- readJPEG('images/dandelion.jpeg')
red <- img[,,1]
green <- img[,,2]
blue <- img[,,3]
df <- data.frame(red=c(red), green=c(green), blue=c(blue))
df <- pivot_longer(df, cols=c('red', 'green', 'blue'), names_to = 'color')
ggplot(df, aes(x=value, group=color, colour=color)) + 
  geom_density(kernel='gaussian') +
  scale_color_manual(values=c('blue', 'green', 'red')) + 
  ggtitle('Pixel Density')
r <- conv2(red, z1, 'valid')
g <- conv2(green, z1, 'valid')
b <- conv2(blue, z1, 'valid')
rgb <- array(dim=c(dim(b), 3))
rgb[,,1] <- r
rgb[,,2] <- g
rgb[,,3] <- b
```

```{r}
layout <- c(1,1)
op <- par(
  mar = c(1, 1, 1, 1),
  mfrow = layout,
  bty = "n",
  omi = c(0, 0, 0, 0)
)
#First image
dims <- dim(rgb)
plot(
  c(0, dims[1]),
  c(dims[2], 0),
  type = "n",
  xlab = "",
  ylab = "",
  xaxt = "n",
  yaxt = "n",
  frame.plot = FALSE,
  main = "Gaussian Blur"
)
rasterImage(rgb, 0, 0, dims[1], dims[2], interpolate = FALSE)
par(op)
```


Working with Uniform Distribution.  

CLT: 
Take K amount of random samples from x. Then take the mean of those K values. Repeat his N amount of times. Create a histogram from all the means. Then plot a curve.
* Sample size should be around 30. 
* Maybe calculate kernal using this 
* Can get mean and SD from CLT

Normal Distribution: 
  Probability on the y axis 
  Likelihood of finding that observation
PDF: Probability Density Function
* Derivative of the CDF
Default is mean = 0 and standard deviation = 1
Density curve
* Look for peaks of frequently occuring values
* Skew: To the left or to the right
  + Many models assume no skew
  + Can inform us about model bias 
* Median: 
* Mean: Center of the curve
* SD: width of the curve 
  + For normal curve 95% of measurements fall between +- 2 sd of the mean
Quantiles
* Waht are thossee
CDF: Cumulative Distribution Function

```{r}
x <- seq(-10, 10, by=.1)
distributions <- data.frame(x, 
                            probability=pnorm(x), 
                            density=dnorm(x), 
                            gauss=gaussian(x)
                            )
ggplot(distributions, aes(x, x)) + geom_line()
#ggplot(pdf, aes(x, y=qnorm(density))) + geom_line()
cdf <- ggplot(distributions, aes(x, y=probability)) + geom_line() + 
  ggtitle("Cumulative Density Function")
pdf <- ggplot(distributions, aes(x, y=density)) + geom_line() + 
  ggtitle("Probability Density Function")
d <- density(x, kernel="gaussian")
df <- data.frame(x=d$x, y=d$y)
grid.arrange(pdf, cdf)
# pdf_plot <- ggplot(pdf, aes(x=probability, y=density)) + geom_line() +
#   ggtitle("Probability Density Function")
rand <- ggplot(mapping=aes(x=rnorm(100), fill="orange")) + geom_density() + 
  ggtitle("Random distribution")
```
